{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPulgQPa8NgxhB9C9NC32Xn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yu741025/MyRepair/blob/using-code-t5-220M-bimodal-model/VulRepair_reproduce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux9JROJcxujD",
        "outputId": "c5c47665-9696-484b-ecb3-e81f1cfe13b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'VulRepair' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/awsm-research/VulRepair.git\n",
        "!cd VulRepair\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/VulRepair/requirements.txt\n",
        "\n"
      ],
      "metadata": {
        "id": "9OGxibidyjrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install numpy\n",
        "!pip install tqdm\n",
        "!pip install pandas\n",
        "!pip install tokenizers\n",
        "!pip install datasets\n",
        "!pip install gdown\n",
        "!pip install tensorboard\n",
        "!pip install scikit-learn\n"
      ],
      "metadata": {
        "id": "X3tfzh_qyoVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "f765cXEQzmjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#original\n",
        "!python /content/VulRepair/M1_VulRepair_PL-NL/vulrepair_main.py \\\n",
        "    --output_dir=./saved_models \\\n",
        "    --model_name=model.bin \\\n",
        "    --tokenizer_name=MickyMike/VulRepair \\\n",
        "    --model_name_or_path=MickyMike/VulRepair \\\n",
        "    --do_test \\\n",
        "    --encoder_block_size 512 \\\n",
        "    --decoder_block_size 256 \\\n",
        "    --num_beams=50 \\\n",
        "    --eval_batch_size 1"
      ],
      "metadata": {
        "id": "c079TJ4_0MP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEr0tFV5oDrl",
        "outputId": "bb41c465-7e95-4a9d-ad66-f1f29cb763ba"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorrt in /usr/local/lib/python3.10/dist-packages (8.6.1.post1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow[and-cuda]==2.14"
      ],
      "metadata": {
        "id": "Sl79r8gUpg6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modified\n",
        "\n",
        "# training\n",
        "\n",
        "!python /content/VulRepair/M1_VulRepair_PL-NL/vulrepair_main.py \\\n",
        "    --model_name=model.bin \\\n",
        "    --output_dir=./saved_models \\\n",
        "    --tokenizer_name=Salesforce/codet5p-220m-bimodal \\\n",
        "    --model_name_or_path=Salesforce/codet5p-220m-bimodal \\\n",
        "    --do_train \\\n",
        "    --epochs 75 \\\n",
        "    --encoder_block_size 512 \\\n",
        "    --decoder_block_size 256 \\\n",
        "    --train_batch_size 4 \\\n",
        "    --eval_batch_size 4 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --max_grad_norm 1.0 \\\n",
        "    --evaluate_during_training \\\n",
        "    --seed 123456  2>&1 | tee train.log"
      ],
      "metadata": {
        "id": "t05lKJG20aDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c52ea17-8879-4f03-a433-6e2b94113412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-15 10:28:01.373747: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-15 10:28:02.396028: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "10/15/2023 10:28:04 - WARNING - __main__ -   device: cuda:0, n_gpu: 1\n",
            "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
            "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
            "10/15/2023 10:28:18 - INFO - __main__ -   Training/evaluation parameters Namespace(output_dir='./saved_models', model_type='t5', encoder_block_size=512, decoder_block_size=256, num_beams=50, model_name='model.bin', checkpoint_model_name='non_domain_model.bin', model_name_or_path='Salesforce/codet5p-220m-bimodal', config_name='', tokenizer_name='Salesforce/codet5p-220m-bimodal', do_train=True, do_test=False, evaluate_during_training=True, train_batch_size=4, eval_batch_size=4, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=123456, epochs=75, n_gpu=1, device=device(type='cuda', index=0))\n",
            "10/15/2023 10:28:20 - WARNING - datasets.builder -   Using custom data configuration MickyMike--cvefixes_bigvul-c7f97ab457d783e4\n",
            "10/15/2023 10:28:20 - WARNING - datasets.builder -   Reusing dataset csv (/root/.cache/huggingface/datasets/csv/MickyMike--cvefixes_bigvul-c7f97ab457d783e4/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
            "10/15/2023 10:28:20 - WARNING - datasets.arrow_dataset -   Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/csv/MickyMike--cvefixes_bigvul-c7f97ab457d783e4/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-3001297705000138.arrow\n",
            "100%|██████████| 594/594 [00:02<00:00, 263.14it/s]\n",
            "10/15/2023 10:28:23 - INFO - __main__ -   *** Example ***\n",
            "10/15/2023 10:28:23 - INFO - __main__ -   label: tensor([[    1, 32106,   273,   374,   274,   963,    67,    88,  1110,    67,\n",
            "          1467,   273,   374,   274,   225, 32106,   596,   274,   289,  1110,\n",
            "            67,  1467,   273, 13726,   261, 11112,    24,    67,    45,   261,\n",
            "         17870,   262,   317,   277,    67,   892,   262,   274,   225, 32106,\n",
            "           317,   277,    67,   892,   269,  1110,    67,  1467,   262,   274,\n",
            "          1663,   542,   261, 19822,   317,   324,    67,   892,   397,  1110,\n",
            "            67,  1467,   269,   374,   269, 17870,   317,   277,    67, 18366,\n",
            "           317,   272,    67,  2629,  1467,   300,  1110,    67,  1467,   225,\n",
            "         32107,   262,   274,  1073,    76,   203,     2,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]])\n",
            "10/15/2023 10:28:23 - INFO - __main__ -   input_ids: tensor([    1,    39,  6950,    17,    29,  6840,   760,   509,  1110,    24,\n",
            "           67,   408,    67,    75,   492,    67,   267,  5979,   261,  1640,\n",
            "           67,    88,   380,  1640,   269,  1958, 17870,   380, 17870,   269,\n",
            "         9088,   509,  2943,   262,   288,  1958,  1110,    24,    67, 18181,\n",
            "           67,  3374,   380,  1073,    76,   274,  1958,  1613,    67,  1978,\n",
            "          380, 19822,   274,  1110,    24,    67,  2556,  3083,    79,    67,\n",
            "           88,   394,  2629,   269, 17683,   273,   374,   274,  1958,  1110,\n",
            "           24,    67,  9565,    67,  2629,   380,  5001,   273, 11112,    24,\n",
            "           67, 14541,   261, 17870,   317,   277,    67, 18366,   262,   317,\n",
            "          272,    67,   281,   274,   509,   393,   273,   374,   274,   225,\n",
            "        32103,   309,   261,  1110,    67,  5979,   261, 17870,   262,   262,\n",
            "          225, 32104, 17683,   273,  1110,    24,    67,  3465,    67,    84,\n",
            "         2629,   261, 11112,    67, 15354,    67,  9199,   261,  1110,    67,\n",
            "          267,   390,    67, 16587,   261, 17870,   262,   262,   262,   274,\n",
            "          309,   261, 17683,   405,   884,  1578,    67,   869,    67, 11447,\n",
            "          261,  5001,   317,   272,    67,  3645,    67,   892,    67,  2629,\n",
            "          262,   262,   288,  2943,  5626, 11112,    24,    67,  7969,    67,\n",
            "           44,  3217,    67, 17805,    67, 16387,  1013,   274, 17683,  1493,\n",
            "          274,   289,   469, 17683,   273,  1110,    24,    67,   267,   390,\n",
            "           67,   869,    67, 27354,    67,  2629,   261, 17870,   262,   274,\n",
            "          394,  2629,   273,  1110,    24,    67,  2704,    67,  3901,    67,\n",
            "         7996,   261,  1640,   269, 17870,   269, 17683,   269,  2943,   269,\n",
            "         3206,   269,   473,   393,   262,   274,   309,   261,   394,  2629,\n",
            "          422,   374,   262,   327,   393,   274, 19822,   273,  2393,    67,\n",
            "          588,  3083,    79,    67,    75,  7944,   261, 17870,   317,   277,\n",
            "           67, 18366,   269,   394,  2629,   269,  1001,    43, 30246,    67,\n",
            "         5980,    58,  2782,   571,   611, 30246,    67,  3417,  4931,   262,\n",
            "          274,   309,   261, 29372,   261,   401, 19822,   262,   262,   327,\n",
            "          300, 25033, 12286,   274,  2176,    67,  4106,   261, 19822,   262,\n",
            "          274,   393,   273,  1110,    24,    67, 22644,    67,   588,    67,\n",
            "         2640,    67,  3860,   261,  1640,   269, 19822,   262,   274,   309,\n",
            "          261,   393,   262,   288,  7186,    67,  4106,   261, 19822,   262,\n",
            "          274,  2897,   596,   274,   289,   225, 32103,  1663,  8501,   261,\n",
            "        19822,   317,   324,    67,   892,   269, 11112,    24,    67,    45,\n",
            "          261, 17870,   262,   317,   277,    67,   892,   269,   225, 32104,\n",
            "          225, 32103, 13726,   261, 11112,    24,    67,    45,   261, 17870,\n",
            "          262,   317,   277,    67,   892,   262,   262,   274,   225, 32104,\n",
            "         1073,    76,   273,  1110,    67,  2629,    67, 16587,   261, 19822,\n",
            "          262,   274,   309,   261,  1110,    67,  5979,   261, 17870,   262,\n",
            "          262,  1073,    76,   317, 20124,    67,  1896,   273,  8326,    67,\n",
            "          869,    67,   298,  2313,   261,  1110,    24,    67,   408,    67,\n",
            "         2981,    67,  2629,    67,  3465,   261, 17870,   269,   374,   262,\n",
            "          262,   274,   469,  1073,    76,   317, 20124,    67,  1896,   273,\n",
            "         8326,    67,   869,    67,   298,  2313,   261,  1110,    24,    67,\n",
            "          408,    67,  2981,    67,  2629,   261, 17870,   269,   374,   262,\n",
            "          262,   274,  1073,    76,   317, 20124,    67, 11179,   273, 11112,\n",
            "           24,    67,  4142,    67,    49, 22247,   274,  1110,    24,    67,\n",
            "        18181,    67,  2629,    67,    71,  1364,    67,   542,   261, 17870,\n",
            "          269,  1073,    76,   262,   274,   444,    67,  4106,    67,  3648,\n",
            "        31756,   261, 19822,   262,   274,  7186,    67,  4106,   261, 19822,\n",
            "          262,   274,   393,   273,  1110,    24,    67,  4110,    67, 18013,\n",
            "           67,     2])\n",
            "10/15/2023 10:28:23 - INFO - __main__ -   decoder_input_ids: tensor([    1, 32106,   273,   374,   274,   963,    67,    88,  1110,    67,\n",
            "         1467,   273,   374,   274,   225, 32106,   596,   274,   289,  1110,\n",
            "           67,  1467,   273, 13726,   261, 11112,    24,    67,    45,   261,\n",
            "        17870,   262,   317,   277,    67,   892,   262,   274,   225, 32106,\n",
            "          317,   277,    67,   892,   269,  1110,    67,  1467,   262,   274,\n",
            "         1663,   542,   261, 19822,   317,   324,    67,   892,   397,  1110,\n",
            "           67,  1467,   269,   374,   269, 17870,   317,   277,    67, 18366,\n",
            "          317,   272,    67,  2629,  1467,   300,  1110,    67,  1467,   225,\n",
            "        32107,   262,   274,  1073,    76,   203,     2,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "10/15/2023 10:28:23 - INFO - __main__ -   *** Example ***\n",
            "10/15/2023 10:28:23 - INFO - __main__ -   label: tensor([[    1, 32106,   317,  1446,    67,  1897,   274,   423,    40,    67,\n",
            "            56, 10687,   261,   293,   306,   374,   308,   262,   274,   225,\n",
            "         32106,   648, 29204,    67, 13584,    67,   734,   294,   423,    40,\n",
            "            67,    56, 10687,    22,   261,   293,   306,   374,   308,   269,\n",
            "           576,   262,   274,   225, 32106,   648, 29204,    67, 13584,    67,\n",
            "           734,   294,   423,    40,    67,    56, 10687,    22,   261,   293,\n",
            "           306,   374,   308,   269,   576,   262,   274,   203,     2,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]])\n",
            "10/15/2023 10:28:23 - INFO - __main__ -   input_ids: tensor([    1,    39,  6950,    17, 18473,   760,   509,   525,   318,    77,\n",
            "          457,    67,  2670,    67,  3374,   261,  2901,  2251,  5709,    67,\n",
            "         2116,   380,   290,  2896,   269,  1866,   582,    67,  3001,   380,\n",
            "          293,   269,  1866,  1958,   293,  5909,    67,  5465,   451,  3069,\n",
            "          380,   366,   269,  1958,   525,   318,    77,   457,    67,    80,\n",
            "           22,  1376,    67,    88,   380,   328,    22,  1376,   262,   288,\n",
            "         1866,  1958,   525,   318,    77,   457,    67,  8417,    67,  2121,\n",
            "           67,    88,   380, 12423,   273,   525,   318,    77,   457,    67,\n",
            "         8417,    67,  2121,   274,   582,    67,   474,  2067,   269,   525,\n",
            "        16769,    67,   408,    67,  1897,   269,   525, 16769,    67,  3374,\n",
            "           67,  1897,   273,   374,   274,  2254,    28,    67,    88,   268,\n",
            "         3070,    67,   723,   269,   268,  3070,    67,  1897,   274,  2254,\n",
            "         1578,    67,    88,  3325,    67,  1095,   274,   509,   268,  3070,\n",
            "           67,  1132,   274,  1866,   582,    67,  3001,   380,   268,  6723,\n",
            "          274,   328,    22,  1376,   317,  1446,    67,  1897,   273,   374,\n",
            "          274,   328,    22,  1376,   317,  3878,    67,  1897,   273,   374,\n",
            "          274,   328,    22,  1376,   317,  3760,   273,   374,   274,   328,\n",
            "           22,  1376,   317,   769,   273,   366,   317,   562,   274,   328,\n",
            "           22,  1376,   317,  3474, 28907,   273,   366,   317,  3474, 28907,\n",
            "          274,   423,    40,    67,    56, 10687,    22,   261,   293,   306,\n",
            "          374,   308,   269,  1059,   262,   274,   328,    22,  1376,   317,\n",
            "         2943,   273,   293,   306,   890,   308,   274,   328,    22,  1376,\n",
            "          317,  4068,   273,   293,   306,   890,   308,   473,   804,  2124,\n",
            "         2579,   654,    67,    38, 22026,    67,  8784,    56,    67,   706,\n",
            "          274,   309,   261, 23370,  1268,    67,  3247, 25171,   261,   293,\n",
            "          262,   480,   804,  2124,  2579,   654,    67,    49, 15396,    67,\n",
            "         9931,   262,   288,   423,    40,    67, 19350,   261,   261,   290,\n",
            "         2896,   269,   315,  2135, 32105, 11179,    17,  2696, 32105,  7015,\n",
            "         4442,   262,   262,   274,   327,   374,   274,   289,   309,   261,\n",
            "          290,  2896,   317,   290,  2896,    67,    73,  6420,   262,   423,\n",
            "           40,    67, 19350,   261,   261,   290,  2896,   269,  2213,    23,\n",
            "           87, 32105,     6,   269,   946,    22,   701,   261,   525,   318,\n",
            "           77,   457,    67,  9855,    67,  2372,   269,  5238, 10951,   269,\n",
            "          328,    22,  1376,   317,  4068,   262,   262,   262,   274,   525,\n",
            "        16769,    67,  3374,    67,  1897,   273,  1059,   274,   309,   261,\n",
            "          290,  2896,   317,   290,  2896,    67,    90,  6420,   405,   404,\n",
            "          262,   423,    40,    67, 19350,   261,   261,   290,  2896,   269,\n",
            "         8422,    82,  1695,    88,    46,   318,    77,   457, 32105,  3513,\n",
            "         2203, 32105,  5094, 32105, 14451,    87,  4279,   269,  2831, 17692,\n",
            "           22,   701,   261,   525, 16769,    67,  6420,    67,  2372,   269,\n",
            "          315,  6102,     6,   269,   328,    22,  1376,   317,  2943,   262,\n",
            "          262,   262,   274,   309,   261,   261,   328,    22,  1376,   317,\n",
            "         2943,   473,   804,  2124,  2579,   654,    67,    38, 22026,    67,\n",
            "         4142,   262,   422,   804,  2124,  2579,   654,    67,    38, 22026,\n",
            "           67,  4142,   262,   288,   268,  6723,   273,   293,   397,   525,\n",
            "        16769,    67,  3374,    67,  1897,   274,   423,    40,    67,    56,\n",
            "        10687,    22,   261,   268,  6723,   306,   374,   308,   269,   576,\n",
            "          262,   274,   525, 16769,    67,   408,    67,  1897,   273, 23370,\n",
            "         1268,    67,  2313, 25171,   261,   268,  6723,   262,   274,   525,\n",
            "        16769,    67,  3374,    67,  1897,  1011,   576,   274,   268,  6723,\n",
            "         1011,   576,   274,   525, 16769,    67,  3374,    67,  1897,  1011,\n",
            "          525,     2])\n",
            "10/15/2023 10:28:23 - INFO - __main__ -   decoder_input_ids: tensor([    1, 32106,   317,  1446,    67,  1897,   274,   423,    40,    67,\n",
            "           56, 10687,   261,   293,   306,   374,   308,   262,   274,   225,\n",
            "        32106,   648, 29204,    67, 13584,    67,   734,   294,   423,    40,\n",
            "           67,    56, 10687,    22,   261,   293,   306,   374,   308,   269,\n",
            "          576,   262,   274,   225, 32106,   648, 29204,    67, 13584,    67,\n",
            "          734,   294,   423,    40,    67,    56, 10687,    22,   261,   293,\n",
            "          306,   374,   308,   269,   576,   262,   274,   203,     2,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "10/15/2023 10:28:23 - INFO - __main__ -   *** Example ***\n",
            "10/15/2023 10:28:23 - INFO - __main__ -   label: tensor([[    1, 32106,   727,    67,    84,   269,   727,   274,  1958,  9205,\n",
            "            26,    67,   978,  2116,   380,  2153,   225, 32106,   262,   262,\n",
            "           274,  2153,   273,  4519,    89,    67,   765,    73,  1134,    67,\n",
            "          1117,   261,  1130,   317,  2153,   269,  7313,    67,   995,   329,\n",
            "            67,  1637,    67,  1355,   261,  4343,   262,   262,   274,   225,\n",
            "         32106,   473,  1183,    26,   269,   225, 32107,  2153,   269,   473,\n",
            "           225, 32106,   274,   309,   261,  2153,   225, 32107,   262,   277,\n",
            "          2143,    79,   317,   225, 32106,   317,   277,  2143,    79,    67,\n",
            "           408,    67, 16587,    67,  1897,   273,   225, 32107,  2153,   317,\n",
            "          2153,    67,    74,  1897,   225, 32106,   317,  2153,    67,    74,\n",
            "          1897,   397,   225, 32107,  2153,   317,  2153,    67,    82,    74,\n",
            "          1897,   225, 32106,  2153,   317,  2153,    67,    82,    74,  1897,\n",
            "           225, 32107,   274, 17661,   317,   203,     2,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]])\n",
            "10/15/2023 10:28:23 - INFO - __main__ -   input_ids: tensor([    1,    39,  6950,    17, 23728,   760,   509,   302,   952,    84,\n",
            "           67,    90,    26,    67,  3612,   261,  1958,  7313,   380,  4343,\n",
            "          269,  1958,  7313,  4793,   380,   582,  4793,   269,   509,  3091,\n",
            "           67,  1897,   262,   288,  1958,  7313,  4793,    67,   267,    26,\n",
            "          380,   584,   267,   273,   261,  1958,  7313,  4793,    67,   267,\n",
            "           26,   380,   262,   582,  4793,   274,  1958, 17661,    67,  4071,\n",
            "           67, 15031,   380,   277,  2143,    79,   273, 17661,    67,  2143,\n",
            "           79,   261,  4343,   262,   274,  1958, 17661,    67, 15031,   380,\n",
            "        17661,   273, 17661,    67,  7771,   261,  4343,   262,   274,  1958,\n",
            "         9205,    26,    67,    84,  1376,   380,  1130,   273, 17661,    26,\n",
            "           67,  7771,   261,  4343,   262,   274,  1958,   302,   952,    84,\n",
            "           67, 15031,   380,  9986,   273,   302,   952,    84,    67,  7771,\n",
            "          261,  4343,   262,   274,   225, 32103,  1958,   316,    26,    67,\n",
            "         4793,   380,   272,  4793,   273,  3206,   269,   380,   727,    67,\n",
            "           84,   269,   727,   274,   225, 32104,  1958,  4693,    77,    26,\n",
            "         1183,    26,   274,  1958,  3046,    67,  4099,   380,  3046,   274,\n",
            "          509,  3091,    67,   723,   274,   509,   393,   274,  9986,   317,\n",
            "          302,   952,  1121,    67,  4615,   273, 21533,  4258,    67, 16256,\n",
            "           67, 11935,   274,   309,   261,  3091,    67,  1897,   411, 31793,\n",
            "           26,    67, 13017,    67, 17926,    22, 28615,   262,   327,   300,\n",
            "          512,   706,  2669,   274,   309,   261,   584,   267,   317,  5367,\n",
            "           26,    67,  9309,   480, 10888,    67, 18819,    26,   262,   327,\n",
            "          300,   512,  6799,  3417, 13272,  6354,   274,  1663,   542,   261,\n",
            "          473,  1183,    26,   269,   374,   269, 13726,   261,  1183,    26,\n",
            "          262,   262,   274,   309,   261,  1130,   317,  4556,  2180,   821,\n",
            "          262,   288,  1183,    26,   263,  4693,  1925,   273,   584,   267,\n",
            "          317,  5367,    26,    67,  2426,  1376,   473, 30618,    26,    67,\n",
            "        17430,  5923,    67, 11704,   274,  2971,    26,    67,  7228,    50,\n",
            "           67,  2426,    67,  2738,   261,  1183,    26,   263,  4693,  1925,\n",
            "          262,   274,   309,   261,  1183,    26,   263,  4693,  1925,   473,\n",
            "        30618,    26,    67, 17430, 13545,    67, 11704,   262,   288,  1958,\n",
            "         2359,    26,    67,  2426,  1925,   380,  4693,  1925,   274,  4693,\n",
            "         1925,   273,  1183,    26,    67, 15031,    67,  8664,   261,  4343,\n",
            "          269,  1183,    26,   263,  4693,  1925,   262,   274,   309,   261,\n",
            "         4693,  1925,   422,  3206,   262,   327,   300,   512,   706,  2669,\n",
            "          274,  1183,    26,    67, 15031,    67,  9340,   261,  4693,  1925,\n",
            "          262,   274,   289,   289,   309,   261,  9205,    26,    67,  4793,\n",
            "           67,  2273,   261,   473,   584,   267,   317,  5367,    26,    67,\n",
            "         4793,   262,   262,   584,   267,   317,  5367,    26,    67,  4793,\n",
            "          263,   272,    26,    67,  4793,   306,  4711,   308,   273,   404,\n",
            "          274,  3091,    67,   723,   273,  9205,    26,    67,  4793,    67,\n",
            "          723,   261,   473,   584,   267,   317,  5367,    26,    67,  4793,\n",
            "          262,   274,   309,   261,  3091,    67,   723,   473, 30618,    26,\n",
            "           67, 14142,    67, 12845,  2871,  9053,   262,   327,   300,  6693,\n",
            "         1584,  2124,   862, 18133,   274,   309,   261,  3091,    67,   723,\n",
            "          473, 30618,    26,    67, 14142,    67, 10554, 14922,   262,   288,\n",
            "          309,   261,  3091,    67,  1897,  1545, 13726,   261,  1958,  7313,\n",
            "         4793,    67,   267,    26,   262,   597,   584,   267,   317,  5367,\n",
            "           26,    67,  4887,    67,   350,   262,   288,   309,   261,  4343,\n",
            "          317,  4343,    67,  3653,    67,  5206,    67,   430,   597,  4343,\n",
            "          317,  4343,    67,  3653,    67,  5206,    67,   430,   480,   584,\n",
            "          267,     2])\n",
            "10/15/2023 10:28:23 - INFO - __main__ -   decoder_input_ids: tensor([    1, 32106,   727,    67,    84,   269,   727,   274,  1958,  9205,\n",
            "           26,    67,   978,  2116,   380,  2153,   225, 32106,   262,   262,\n",
            "          274,  2153,   273,  4519,    89,    67,   765,    73,  1134,    67,\n",
            "         1117,   261,  1130,   317,  2153,   269,  7313,    67,   995,   329,\n",
            "           67,  1637,    67,  1355,   261,  4343,   262,   262,   274,   225,\n",
            "        32106,   473,  1183,    26,   269,   225, 32107,  2153,   269,   473,\n",
            "          225, 32106,   274,   309,   261,  2153,   225, 32107,   262,   277,\n",
            "         2143,    79,   317,   225, 32106,   317,   277,  2143,    79,    67,\n",
            "          408,    67, 16587,    67,  1897,   273,   225, 32107,  2153,   317,\n",
            "         2153,    67,    74,  1897,   225, 32106,   317,  2153,    67,    74,\n",
            "         1897,   397,   225, 32107,  2153,   317,  2153,    67,    82,    74,\n",
            "         1897,   225, 32106,  2153,   317,  2153,    67,    82,    74,  1897,\n",
            "          225, 32107,   274, 17661,   317,   203,     2,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "100%|██████████| 84/84 [00:00<00:00, 298.51it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "10/15/2023 10:28:23 - INFO - __main__ -   ***** Running training *****\n",
            "10/15/2023 10:28:23 - INFO - __main__ -     Num examples = 594\n",
            "10/15/2023 10:28:23 - INFO - __main__ -     Num Epochs = 75\n",
            "10/15/2023 10:28:23 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n",
            "10/15/2023 10:28:23 - INFO - __main__ -     Total train batch size = 4\n",
            "10/15/2023 10:28:23 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "10/15/2023 10:28:23 - INFO - __main__ -     Total optimization steps = 11175\n",
            "  0%|          | 0/149 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "!python /content/VulRepair/M1_VulRepair_PL-NL/vulrepair_main.py \\\n",
        "    --output_dir=./saved_models \\\n",
        "    --model_name=model.bin \\\n",
        "    --tokenizer_name=Salesforce/codet5p-2b \\\n",
        "    --model_name_or_path=Salesforce/codet5p-2b --do_test \\\n",
        "    --encoder_block_size 512 \\\n",
        "    --decoder_block_size 256 \\\n",
        "    --num_beams=50 \\\n",
        "    --eval_batch_size 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRQGosAQiV_x",
        "outputId": "5d72437e-14af-40f8-b19a-88f3a6ba0273"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-15 09:17:02.899932: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "10/15/2023 09:17:06 - WARNING - __main__ -   device: cuda:0, n_gpu: 1\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/VulRepair/M1_VulRepair_PL-NL/vulrepair_main.py\", line 393, in <module>\n",
            "    main()\n",
            "  File \"/content/VulRepair/M1_VulRepair_PL-NL/vulrepair_main.py\", line 360, in main\n",
            "    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\", line 701, in from_pretrained\n",
            "    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\", line 534, in get_tokenizer_config\n",
            "    resolved_config_file = cached_file(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 429, in cached_file\n",
            "    resolved_file = hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 110, in _inner_fn\n",
            "    validate_repo_id(arg_value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 158, in validate_repo_id\n",
            "    raise HFValidationError(\n",
            "huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'Salesforce/Salesforce/codet5p-2b'. Use `repo_type` argument if needed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDNN_PATH=$(dirname $(python -c \"import nvidia.cudnn;print(nvidia.cudnn.__file__)\"))\n",
        "!export LD_LIBRARY_PATH=$CUDNN_PATH/lib:$CONDA_PREFIX/lib/:$LD_LIBRARY_PATH\n"
      ],
      "metadata": {
        "id": "hjVp9XF_kTkH"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}